{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["All modules have been imported\n"]},{"ename":"OSError","evalue":"No file or directory found at eyenetics-ml-model.h5","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll modules have been imported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39meyenetics-ml-model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m converter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(model)\n\u001b[0;32m     45\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mconvert()\n","File \u001b[1;32mc:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\saving\\saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    205\u001b[0m         filepath,\n\u001b[0;32m    206\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    207\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    208\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m    213\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    214\u001b[0m )\n","File \u001b[1;32mc:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\saving\\legacy\\save.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m         )\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    235\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    236\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    237\u001b[0m         )\n","\u001b[1;31mOSError\u001b[0m: No file or directory found at eyenetics-ml-model.h5"]}],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","from PIL import Image\n","import scipy\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.losses import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.preprocessing.image import *\n","from tensorflow.keras.utils import *\n","from sklearn.neural_network import MLPClassifier\n","# import pydot\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import *\n","from sklearn.model_selection import *\n","import tensorflow.keras.backend as K\n","\n","from tqdm import tqdm, tqdm_notebook\n","from colorama import Fore\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from glob import glob\n","from skimage.io import *\n","%config Completer.use_jedi = False\n","import time\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import lightgbm as lgb\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n","\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"All modules have been imported\")\n","model = load_model('eyenetics-ml-model.h5')\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["info=pd.read_csv(\"../input/prepossessed-arrays-of-binary-data/1000_Binary Dataframe\")\n","info=info.drop('Unnamed: 0',axis=1)\n","info.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["info.level.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.set_style('darkgrid')\n","fig, ax = plt.subplots(figsize=(10,5))\n","sns.barplot(x=info.level.unique(),y=info.level.value_counts(),palette='Blues_r',ax=ax)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sizes = info['level'].values\n","sns.distplot(sizes, kde=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Binary_90 = np.load('../input/prepossessed-arrays-of-binary-data/1000_Binary_images_data_90.npz')\n","X_90=Binary_90['a']\n","Binary_128 = np.load('../input/prepossessed-arrays-of-binary-data/1000_Binary_images_data_128.npz')\n","X_128=Binary_128['a']\n","Binary_264 = np.load('../input/prepossessed-arrays-of-binary-data/1000_Binary_images_data_264.npz')\n","X_264=Binary_264['a']\n","y=info['level'].values\n","\n","\n","print(X_90.shape)\n","print(X_128.shape)\n","print(X_264.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Shape before reshaping X_90\" +str(X_90.shape))\n","X_90=X_90.reshape(1000,90,90,3)\n","print(\"Shape after reshaping X_90\" +str(X_90.shape))\n","print(\"\\n\\n\")\n","\n","print(\"Shape before reshaping X_128\" +str(X_128.shape))\n","X_128=X_128.reshape(1000,128,128,3)\n","print(\"Shape after reshaping X_128\" +str(X_128.shape))\n","print(\"\\n\\n\")\n","\n","print(\"Shape before reshaping X_264\" +str(X_264.shape))\n","X_264=X_264.reshape(1000,264,264,3)\n","print(\"Shape after reshaping X_264\" +str(X_264.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.title(\"90*90*3 Image\")\n","plt.imshow(X_90[1])\n","plt.show()\n","\n","plt.title(\"128*128*3 Image\")\n","plt.imshow(X_128[1])\n","plt.show()\n","\n","plt.title(\"264*264*3 Image\")\n","plt.imshow(X_264[1])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X=np.array(X_264)\n","Y=np.array(y)\n","# Y=to_categorical(Y,5)\n","x_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.4, random_state=42)\n","x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.5, random_state=42)\n","print(len(x_train),len(x_val),len(x_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y1=pd.DataFrame(Y)\n","Y1.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dnn_model=Sequential()\n","dnn_model=Sequential()\n","dnn_model.add(Dense(8, input_dim=3, kernel_initializer = 'uniform', activation = 'relu'))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(128, kernel_initializer = 'uniform', activation = 'relu'))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(256, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(128, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu' ))\n","dnn_model.add(BatchNormalization())\n","dnn_model.add(Dropout(0.2))\n","dnn_model.add(Dense(3,activation='softmax'))\n","dnn_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n","    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n","    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy)) \n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","                          \n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","          \n","    print(\"-\"*80)\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= ResNet50(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn import pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","    \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","   \n","    print('------------------------ Test Set Metrics------------------------')\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    \n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= VGG16(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['accuracy'],)\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= VGG19(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= ResNet101(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= MobileNetV2(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= MobileNet(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= MobileNet(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= InceptionResNetV2(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= InceptionResNetV2(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= InceptionResNetV2(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model= InceptionResNetV2(input_shape=(264,264,3), weights='imagenet', include_top=False)\n","x = base_model.output\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = BatchNormalization()(x)\n","x = Dense(16,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(32,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256,kernel_initializer='he_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","model_feat = Model(inputs=base_model.input,outputs=predictions)\n","\n","train_features = model_feat.predict(x_train)\n","val_features=model_feat.predict(x_val)\n","test_features=model_feat.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.pipeline import Pipeline\n","names = [\n","        \"K Nearest Neighbour Classifier\",\n","        'SVM',\n","        \"Random Forest Classifier\",\n","        \"AdaBoost Classifier\", \n","        \"XGB Classifier\",\n","        \"MLP Classifier\"\n","         ]\n","classifiers = [\n","    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n","    SVC(),\n","    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n","    AdaBoostClassifier(),\n","    XGBClassifier(),\n","    MLPClassifier()\n","        ]\n","zipped_clf = zip(names,classifiers)\n","def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n","    sentiment_fit = pipeline.fit(X_train, y_train)\n","    \n","    y_pred_train= sentiment_fit.predict(X_train)\n","    y_pred_val = sentiment_fit.predict(X_val)\n","    y_pred_test = sentiment_fit.predict(X_test)\n","    \n","    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n","    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n","    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n","    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n","    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n","    \n","    \n","    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n","    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n","    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n","    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n","    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n","   \n","    \n","    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n","    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n","    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n","    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n","    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n","  \n","    \n","    \n","    print()\n","    print('------------------------ Train Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy core : {}%\".format(train_accuracy))\n","    \n","    print('------------------------ Validation Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(val_accuracy))\n","    print('------------------------ Test Set Metrics------------------------')\n","    print()\n","    print(\"Accuracy score : {}%\".format(test_accuracy))\n","    print(\"F1_score : {}\".format(test_F1))\n","    print(\"Kappa Score : {} \".format(test_kappa))\n","    print(\"Recall score: {}\".format(test_recall))\n","    print(\"Precision score : {}\".format(test_precision))\n","    \n","    print(\"-\"*80)\n","    print()\n","    \n","def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n","    result = []\n","    for n,c in classifier:\n","        checker_pipeline = Pipeline([('Classifier', c)])\n","        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n","        #print(c)\n","        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_y=to_categorical(y_train,3)\n","val_y=to_categorical(y_val,3)\n","test_y=to_categorical(y_test,3)\n","dnn_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n","history = dnn_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\n","loss_value , accuracy = dnn_model.evaluate(train_features, train_y)\n","print('Train_accuracy is:' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(val_features, val_y)\n","print('Validation_accuracy is := ' + str(accuracy))\n","loss_value , accuracy = dnn_model.evaluate(test_features, test_y)\n","print('test_accuracy is : = ' + str(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n","knn.fit(train_features, y_train)\n","plot_confusion_matrix(knn, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC()\n","svc.fit(train_features, y_train)\n","plot_confusion_matrix(svc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rf = RandomForestClassifier()\n","rf.fit(train_features, y_train)\n","plot_confusion_matrix(rf, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ada = AdaBoostClassifier()\n","ada.fit(train_features, y_train)\n","plot_confusion_matrix(ada, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xgbc = XGBClassifier()\n","xgbc.fit(train_features, y_train)\n","plot_confusion_matrix(xgbc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlpc = MLPClassifier()\n","mlpc.fit(train_features, y_train)\n","plot_confusion_matrix(mlpc, test_features, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tf.saved_model.save\n","with open('model.tflite', 'wb') as f:\n","    f.write(tflite_model)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
